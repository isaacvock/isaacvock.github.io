[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "In this blog, I plan to discuss the following topics:\n\nAnything and everything nucleotide recoding RNA-seq (NR-seq). Other metabolic labeling RNA-seq extensions are also potentially free game.\nThe use of statistics in bioinformatics. I developed a course on this topic and will use this setting to post some of my class material in blog format.\n\nI am also excited to use this as a platform to play around with the recently developed Quarto Live!"
  },
  {
    "objectID": "posts/nrseq_analysis/index.html",
    "href": "posts/nrseq_analysis/index.html",
    "title": "Analyzing NR-seq data: the basics",
    "section": "",
    "text": "In my last post, I introduced NR-seq by walking through the development of an NR-seq simulator. That post implicitly introduced some of the complexities of interpreting NR-seq data. In this post, we will tackle these challenges head-on and build up a rigorous strategy by which to analyze NR-seq data. We will do this in a piece-meal fashion, first developing a simple but flawed strategy, until eventually working up to mixture modeling (the current gold-standard for NR-seq analyses). No statistical model is perfect though, so we will finish with a discussion and exploration of the limitations of this gold-standard."
  },
  {
    "objectID": "posts/nrseq_analysis/index.html#nr-seq-a-reminder",
    "href": "posts/nrseq_analysis/index.html#nr-seq-a-reminder",
    "title": "Analyzing NR-seq data: the basics",
    "section": "NR-seq: a reminder",
    "text": "NR-seq: a reminder\nIn an NR-seq experiment, there are two populations of RNA: those synthesized in the presence of label (a.k.a. labeled, or new, RNA) and those which were synthesized prior to metabolic labeling (a.k.a unlabeled, or old, RNA). The first task of any NR-seq analysis is for a given species of RNA (e.g., RNA transcribed from a particular gene), quantify the relative amounts of these two populations. This is referred to as that species’ “fraction new” or “new-to-total ratio (NTR)”. Downstream analyses are then aimed at interpreting these fraction news/NTRs. This post will only concern itself with fraction new estimation. I will use the term “fraction new” for the remainder of this post.\nTo estimate the fraction new, we rely on the mutational content of mapped sequencing reads. NR-seq involves chemically recoding metabolic label (e.g., s4U) so that reverse transcriptase reads it as a different nucleotide (e.g., a cytosine). Thus, reads from new RNA will have, on average, more mutations than reads from old RNA. This observation is the key to analyzing NR-seq data.\nTo test the strategies discussed, we will use simulated data. This allows us to know the ground truth and explore the robustness of any approach. Here is the function that we will use to simulate data, as well as some helper functions we can use to assess analysis strategies:"
  },
  {
    "objectID": "posts/nrseq_analysis/index.html#a-simple-approach-mutational-cutoffs",
    "href": "posts/nrseq_analysis/index.html#a-simple-approach-mutational-cutoffs",
    "title": "Analyzing NR-seq data: the basics",
    "section": "A simple approach: mutational cutoffs",
    "text": "A simple approach: mutational cutoffs\nIf reads from new RNA have more mutations on average than those from old RNA, maybe we can just use a simple mutational cutoff to classify individual reads as from old or new RNA. The fraction of reads that come from the latter is then our estimate for the fraction new. This approach has been popular since the advent of NR-seq, and is implemented in popular bioinformatic tools for analyzing NR-seq data like SLAMDUNK. Let’s simulate some data and test out this approach\n\n\n\n\n\n\n\n\nIf you run this code with the default simulation parameters, you’ll see that the estimates are decent. The 1+ mutation cutoff for newness looks better than the 2+ cutoff, with the former yielding estimates that consistently correlate pretty well with the simulated ground truth.\nSo that’s all it takes to analyze NR-seq data? Not so fast. In our simulation, there is a default metabolic label incorporation + conversion rate of 5%. While this is a standard “good” incorporation rate, if you analyze as many NR-seq datasets as I have you will quickly notice that there is a lot of dataset-to-dataset variation in the incorporation rate. For example, there is a tremendous amount of cell line-to-cell line variation in the readiness of s4U incorporation, with some cell lines (e.g., HEK293 and HeLa) uptaking s4U with great tenacity and others (e.g., neuronal cell lines) having typically much lower s4U incorporation rates. In addition, incorporation rates also can correlate with biological condition. For example, knocking out key factors in RNA metabolism (e.g., degradation factors) can significantly impact incorporation rates. In general, incorporation rates seem to correlate strongly with general metabolic rates, and anything that perturbs these rates will likely affect incorporation rates.\nThis lattermost observation is particularly dangerous when it comes to applying the simple mutation content cutoff analysis strategy. Often, we don’t just care about what an RNA’s dynamics look like in one biological condition, but rather how it differs between two more different conditions (e.g., WT vs. KO of your favorite gene, untreated vs. drug treated, etc.). If an analysis method is not robust to variation in incorporation rates, it risks making technical variability look like biological signal.\nThus, what happens if we simulate a different incorporation rate? If you tweak the simulation above (set pnew in simulate_nrseq() to a different value than its default of 0.05 and rerun code):\n\n\n\nAccuracy of cutoff approach for range of pnews\n\n\nThe key takeaway from this investigation is that the accuracy of the cutoff-based approach is heavily reliant on the incorporation rate. Since incorporation rate often correlates with biology, this represents a dangerous confounder for mutation cutoff analyses. We need a more robust analysis strategy."
  },
  {
    "objectID": "posts/nrseq_analysis/index.html#a-better-idea-statistical-modeling",
    "href": "posts/nrseq_analysis/index.html#a-better-idea-statistical-modeling",
    "title": "Analyzing NR-seq data: the basics",
    "section": "A better idea: statistical modeling",
    "text": "A better idea: statistical modeling\nThe problem with the cutoff based approach is two-fold:\n\nIt’s possible for reads from labeled RNA to have no mutations. This is because the metabolic label has to compete with the regular nucleotide for incorporation, which is what keeps incorporation rates relatively low in most NR-seq experiments.\nIt’s possible for reads from unlabeled RNA to have mutations. This can be due to RT errors, sequencing errors, alignment errors, unmasked SNPs, etc.\n\nThus, a mutation in a read does not make it definitively from new RNA, and a lack of mutations does not make it definitively from old RNA. How can we navigate this inherent uncertainty? This is exactly what statistical modeling was built for.\nStatistical modeling first means coming up with a model that specifies how likely every possible data point is. If you tell me the number of mutable nucleotides, the number of mutations in a read, whether it came from old or new RNA, and whatever can be specified about the process by which mutations arise in reads, I should be able to use this model to calculate a likelihood for that piece of data.\n\n\n\n\n\n\nWhat is a data point’s “likelihood”?\n\n\n\n\n\nThe likelihood of a data point is the probability of seeing that data, given all of the information you provided, often written as P(data | parameters). In this case, we are dealing with discrete data (integer mutation counts), meaning that this likelihood can also be interpreted as the probability of getting that data point given all of the specified parameters. In a continuous setting, interpreting this is a bit more complicated, as the probability of any specific continuous outcome is 0.\n\n\n\nIn practice, this often involves specifying a convenient to work with probability distribution that describes the variability in your data. To do this, you need to make some assumptions about your data. For NR-seq data, it is common to assume:\n\nFor reads from new RNA, there is a set probability (call it pnew) that a given mutable nucleotide (e.g., uridines in an s4U labeling NR-seq experiment) is mutated. This pnew is the same for all such reads, regardless of the RNA species of origin.\nFor reads from old RNA, there is also a set probability of mutation (call it pold) for all such reads.\nAll nucleotides are independent. Whether or not a given nucleotide is mutated has no impact on the probability that other nucleotides in that read are also mutated (given the status of the read as coming from old or new RNA).\n\nThese are actually the exact assumptions that we used to simulate data above and in the introduction to NR-seq blog. These assumptions lend themselves to a particular model: a two-component binomial mixture model.\n\nTwo-component binomial mixture model\n“Two-component binomial mixture model” is a mouthful, so let’s break it down.\n“Two-component” = the model supposes that there are two populations in your data. In our case, this is reads from old RNA and reads from new RNA.\n“binomial” = data from each of the populations is modeled as following a binomial distribution. We’ve seen this distribution in the intro to NR-seq post. It describes a situation where you have a certain number of independent “trials” (e.g., mutable nucleotides), with a set probability of “success” (e.g., mutation of the nucleotide) for each trial.\n“mixture model” = you don’t know which population any given data point comes from. This is known as a “latent-variable model”, which can pose some computational challenges when trying to estimate the parameters of such a model. These challenges will turn out to be fairly easy to navigate in this setting, but will limit our efforts to extend and improve this model in future sections.\nTo summarize, we are assuming that each sequencing read comes from one of two populations: old RNA or new RNA. The mutational content of both types of reads is well modeled as following a binomial distribution. The parameters of these binomial distributions are the number of mutable nucleotides and the probability that each of these nucleotides gets mutated. We don’t need to estimate the number of mutable nucleotides (this is just more data), but we do not know a priori the two mutation rates. Thus, we need to estimate these two parameters, as well as the quantity of primary interest: the fraction new. We can schematize this model as such:\n\n\n\nTwo-component binomial mixture model"
  },
  {
    "objectID": "posts/nrseq_analysis/index.html#fitting-a-two-component-binomial-mixture-model",
    "href": "posts/nrseq_analysis/index.html#fitting-a-two-component-binomial-mixture-model",
    "title": "Analyzing NR-seq data: the basics",
    "section": "Fitting a two-component binomial mixture model",
    "text": "Fitting a two-component binomial mixture model"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Isaac’s blog",
    "section": "",
    "text": "Analyzing NR-seq data: the basics\n\n\n\n\n\n\nnrseq\n\n\n\n\n\n\n\n\n\nDec 22, 2024\n\n\nIsaac Vock\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing NR-seq by simulating NR-seq\n\n\n\n\n\n\nnrseq\n\n\n\n\n\n\n\n\n\nDec 16, 2024\n\n\nIsaac Vock\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnrseq\n\n\nstats\n\n\n\n\n\n\n\n\n\nDec 13, 2024\n\n\nIsaac Vock\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "My main projects",
    "section": "",
    "text": "Introduced Snakemake pipeline (fastq2EZbakR) and R package (EZbakR)\nGeneralizes feature assignment: the set of annotated genomic features that you can perform analyses on.\nGeneralizes mixture modeling: how the fraction of reads from labeled RNA are estimated.\nGeneralizes dynamical systems modeling: how kinetic parameters are estimated from NR-seq data.\nGeneralizes comparative analyses: how kinetic parameters are compared across biological conditions.\n\nLink to preprint"
  },
  {
    "objectID": "about.html#the-ezbakr-suite",
    "href": "about.html#the-ezbakr-suite",
    "title": "My main projects",
    "section": "",
    "text": "Introduced Snakemake pipeline (fastq2EZbakR) and R package (EZbakR)\nGeneralizes feature assignment: the set of annotated genomic features that you can perform analyses on.\nGeneralizes mixture modeling: how the fraction of reads from labeled RNA are estimated.\nGeneralizes dynamical systems modeling: how kinetic parameters are estimated from NR-seq data.\nGeneralizes comparative analyses: how kinetic parameters are compared across biological conditions.\n\nLink to preprint"
  },
  {
    "objectID": "about.html#bakr",
    "href": "about.html#bakr",
    "title": "My main projects",
    "section": "bakR",
    "text": "bakR\n\nSummary\n\n\n\nIntroduced an R package (bakR) designed to compare RNA synthesis and degradation rate constants across biological conditions.\nAlso introduced a hierarchical modeling strategy to increase statistical power of these comparisons.\n\nLink to paper"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Isaac Vock",
    "section": "",
    "text": "I am a PhD student at Yale University in the lab of Matthew Simon. I have developed a number of bioinformatic tools for processing and analyzing nucleotide recoding RNA-seq (NR-seq) experiments. NR-seq is a class of methods for quantifying the kinetics of RNA synthesis and degradation, and includes methods like TimeLapse-seq (developed in the Simon lab), SLAM-seq, TUC-seq, etc. These are powerful tools that are allowing us to study the dynamic lives of RNA at unprecedented resolution, and I have had a lot of fun dreaming up ways in which we can extract exciting biological insights from NR-seq data.\nI am also a statistician, and have developed a number of novel methods for analyzing NR-seq data. One of my passions is helping biologists better understand the statistical methods powering their favorite bioinformatic tools. This led me to develop a course at Yale called “Statistical Intuition for Modern (RNA) Biochemists”. It’s inspired by Susan Holmes and Wolfgang Huber’s book of a similar title and Richard McCelreath’s cultural phenomenon “Statistical Rethinking”. It aims to be an accessible introduction to statistics for biochemistry majors. We will be covering the basic machinery of statistical modeling and its use in popular methods like linear modeling and clustering. Rather than relying on mathematical formalism to convey these concepts though, we will be making use of simulations and interactive exercises to help students develop an intuition for key concepts. Finally, we will start the course by introducing student’s to RNA-seq, so as to have a common data language that we can connect all conecpts back to. Eventually, all of the course material will be hosted at this repo."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Isaac Vock",
    "section": "Education",
    "text": "Education\n\n\nYale University | New Haven, CT | August 2019 - Present\nPhD in Molecular Biophysics and Biochemistry\n\n\nCentre College | Danville, KY | August 2015 - May 2019\nB.S. in Physics, minor in Math"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Isaac Vock",
    "section": "Experience",
    "text": "Experience\n\n\nProgramming in R (since 2019)\nScripting (example repo)\nR package development (most notably, EZbakR)\nShiny app development (e.g., interactive TimeLapse-seq simulator)\n\n\nSnakemake pipeline development (since 2021)\nfastq2EZbakR: Flexible processing of NR-seq data.\nNRsim: Simulating NR-seq data to test analysis strategies and pipelines.\nAnnotationCleaner: Assembling annotations using StringTie and some custom scripts.\nTHE_Aligner: Aligning almost any kind of RNA-seq data.\nPROseq_etal: PRO-seq/ChIP-seq/ATAC-seq pipeline.\n\n\nOther experience\nPython (since 2021; used throughout Snakemake pipelines listed above)\nC (since 2023; example repo)\nPytorch (since 2023; example repo)"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Introducing NR-seq by simulating NR-seq",
    "section": "",
    "text": "Nucleotide recoding RNA-seq (NR-seq; SLAM-seq, TimeLapse-seq, TUC-seq, etc.), is a set of methods to probe the dynamics of RNA. These methods use metabolic labeling. In this case, metabolic labeling means treating cells with a molecule that looks like a regular nucleotide (e.g., 4-thiouridine, or s4U), which cells incorporate into nascent RNA. NR-seq then employs a chemistry to modify the metabolic label so that a reverse transcriptase identifies it as a nucleotide different from what it originally mimiced (e.g., recoding s4U as a cytosine analog). This allows label incorporation events to be bioinformatically detected as apparent mutations in aligned sequencing reads.\nThis post introduces the main ideas behind the modeling of NR-seq data."
  },
  {
    "objectID": "posts/post-with-code/index.html#a-brief-introduction-to-nr-seq",
    "href": "posts/post-with-code/index.html#a-brief-introduction-to-nr-seq",
    "title": "Introducing NR-seq by simulating NR-seq",
    "section": "A brief introduction to NR-seq",
    "text": "A brief introduction to NR-seq\n\n\n\nSchematic of an NR-seq experiment. Adapted from Schofield et al. 2018.\n\n\nDeveloping a mechanistic understanding of gene expression regulation requires methods to probe the kinetics of RNA synthesis, processing, and degradation. While standard RNA-seq begins to solve this problem, it provides limited information about the kinetics of the processes which determine an RNA’s abundance. Nucleotide recoding RNA-seq (NR-seq; TimeLapse-seq, SLAM-seq, TUC-seq, etc.) overcomes these limitations. NR-seq combines metabolic labeling with novel chemistries that recode the hydrogen bonding pattern of a metabolic label so as to facilitate detection of labeled RNA via these chemically induced mutations in sequencing reads, absolving the need for biochemical enrichment of labeled RNA. By providing information about both overall RNA abundance and the dynamics of nascent and pre-existing RNA, NR-seq resolves the kinetic ambiguities of standard RNA-seq.\nOne way to intuit how metabolic labeling provides information about the dynamics of RNA is to consider one of the populations being tracked: the old, unlabeled RNA. Since this RNA can only degrade, its dynamics are entirely determined by its turnover kinetics. Combining this with the abundance information provided by standard RNA-seq provides information about the RNA’s synthesis kinetics (transcription + processing)."
  },
  {
    "objectID": "posts/post-with-code/index.html#understanding-nr-seq-by-simulating-nr-seq",
    "href": "posts/post-with-code/index.html#understanding-nr-seq-by-simulating-nr-seq",
    "title": "Introducing NR-seq by simulating NR-seq",
    "section": "Understanding NR-seq by simulating NR-seq",
    "text": "Understanding NR-seq by simulating NR-seq\nHere, we will walk through a basic simulation of NR-seq data to give you a sense as to how to think about and interpret NR-seq data.\n\nThe full shebang\nBelow is a summary of the entire simulation which we will walk through piece by piece in the following sections.\n\n\n\n\n\n\n\n\n\n\nMutable nucleotide content\nDifferent RNAs have different nucleotide content. Sequencing reads in standard short read sequencing experiments typically only sample a small portion of the entire RNA, and thus reads from a given species of RNA will also vary in their nucleotide content. In a standard NR-seq experiments, uridines in an RNA synthesized in the presence of metabolic label have an opportunity to be replaced with s4U. This, we need to simulate the number of Us in each read (prior to nucleotide recoding). Since we typically sequence cDNA, and this is also best thought as the number of Ts in the genomic sequence to which a given read aligned, we will refer to this as the number of T’s.\nLet’s consider simulating sequencing reads from a specific RNA species (e.g., a particular transcript isoform) first. In this case, the RNA will have a particular U-content, i.e., the fraction of nucleotides in its exonic sequence that are U’s. This is a simulation parameter, along with the number of reads we want to simulate, and the length of each read. It’s simplest to assume that each nucleotide in a read has some set probability of being a U, and that this probability is the same for all nucleotides. In this case, we can draw the number of U’s (or cDNA T’s) from a binomial distribution:\n\n\n\n\n\n\n\n\n\n\nMutational content\nThe number of mutations in an NR-seq sequencing read provides the information necessary to classify it as having come from either labeled or unlabeled RNA. If a read is from labeled RNA (or RNA that was synthesized during the label time; a given RNA molecule may not incorporate any metabolic label even if it could have), the mutational content of that read is a function of the following things:\n\nHow many mutable nucleotides are contained in the read, which we simulated above.\nHow often the metabolic label is incorporated in place of the standard nucleotide. We will also lump into this term the chemical efficiency of recoding, which is usually pretty high (&gt; 80%).\nThe background mutation rate, due to sequencing/RT/PCR errors, alignment errors, SNPs, etc.\n\nWe’ve already simulated the first factor. The other two are parameters that we will include in our simulation. Incorporation rates in successful NR-seq experiments are typically around 5%, and background mutation rates can range from nearly 0% to around 0.4%, depending on a number of factors. 0.2% is a fairly typical background mutation rate in my experience.\nFinally though, we need to determine the “newness” status of each sequencing read. Each species of RNA will have a characteristic “fraction new”, which is the fraction of RNA molecules present at RNA extraction time that were exposed to metabolic label. We can then model sequencing reads as being randomly drawn from this pool, with fraction new probability of sampling a labeled RNA. These processess are all well modeled with binomial distributions, so simulating all of this looks like:\n\n\n\n\n\n\n\n\nSome observations from the above visualizations:\n\nSome reads from unlabeled RNA have mutations. This is due to the non-zero background mutation rate.\nSome reads from labeled RNA have no mutations. This is due to the incorporation rate being much less than 100%. Experimentally, this is due to the metabolic label having to compete with the regular nucleotide for incorporation into nascent RNA.\n\nThese observations are what make analyzing NR-seq data challenging, and what will motivate analysis strategies discussed in other posts.\n\n\nRNA kinetics and NR-seq\nDifferent transcript isoforms can have very different properties. Of importance to an NR-seq experiment, different isoforms can differ in their nucleotide content and turnover kinetics. The latter’s impact is obvious, but my reason for bringing up the former may not be. In short, the rate at which a given isoform is degraded will determine its fraction new.\nTo see why turnover kinetics of RNA influences NR-seq data, consider the following model:\nIn it, RNA’s are synthesized at some rate ksyn, and degraded with a rate constant kdeg. kdeg is related to the average lifetime of a given RNA. When the rate at which a given species of RNA is degraded (kdeg * the amount of RNA that exists to be degraded) is equal to the rate at which it is synthesized (ksyn), that RNA is said to be at steady-state. A bit of algebra reveals that this occurs when the levels of RNA are equal to ratio of the synthesis and degradation rate constants:\n\\[\n\\begin{aligned}\n\\text{ksyn} & = \\text{kdeg}*[\\text{RNA}]_{\\text{ss}} \\\\\n\\frac{\\text{ksyn}}{\\text{kdeg}} & = [\\text{RNA}]_{\\text{ss}}\n\\end{aligned}\n\\]\nWhen you add metabolic label, you effectively create two species of RNA with distinct dynamics:\n\nOld RNA that existed at the time of labeling. These can only degrade and are no longer synthesized. In this model, this means that they exponentially degrade with rate constant kdeg.\nNew RNA that is synthesized during labeling. These will slowly accumulate to steady-state levels as they are both synthesized and degraded.\n\nAssuming that the synthesis and degradation rate constants are constant throughout the label time, the dynamics of old and new RNA looks like:\n\n\n\n\n\n\n\n\nBecause the rate constants are unchanging, so is the total amount of RNA at any given time. Thus, the amount of Old RNA + New RNA = steady-state RNA level. Because of this, there is a simple relationship between the turnover kinetics of an RNA and the fraction new (abbreviated fn) for that RNA:\n\\[\n\\begin{aligned}\n\\text{fn} &= \\frac{[\\text{New RNA}]}{[\\text{RNA}]} \\\\\n\\text{fn} &= \\frac{[\\text{RNA}]_{\\text{ss}}\\ast(1 - e^{-\\text{kdeg}\\ast \\text{tl}})}{[\\text{RNA}]_{\\text{ss}}} \\\\\n\\text{fn} &= 1 - e^{-\\text{kdeg}\\ast \\text{tl}}\n\\end{aligned}\n\\] where tl is the amount of time for which the cells were labeled. This simple relationship reveals some of the power of NR-seq. NR-seq provides information about RNA kinetics inaccessible to analyses of standard RNA-seq data (i.e., read counts). We can also use this relationship to modify our simulation and set the more biologically interpretable degradation rate constant rather than the fraction new:\n\n\n\n\n\n\n\n\n\n\nSimulating multiple transcripts\nSo far, we have focused on simulating data for a single transcript. In actuality, NR-seq is a high throughput method that provides information about all of the appreciably expressed transcripts in the cells from which you extracted RNA. Thus, we can set the number of transcripts we would like to simulate, and then draw kinetic parameters from a chosen distribution.\nOne thing we need to consider though is how the rate constants give rise to expected read counts for each transcript. We have discussed how the steady-state levels of a given RNA are a function of its synthesis and degradation rate constants, but is an RNA’s abundance related to its RNA-seq coverage?\nThe answer comes from realizing that RNA-seq is a measure of relative RNA abundance, not absolute abundance. That is, the number of reads you get from an RNA is a function of how abundant that RNA is, relative to all other RNAs in the sequenced pool. In addition, abundance in this setting is a function not only of the molecular abundance of an RNA (i.e., the number of molecules of that RNA present in the average cell), but also of the length of the RNA. This is because we are sequencing short fragments of an RNA, and thus the probability that we sequence a fragment from a given RNA depends on how many fragments in our pool come from that RNA. This is roughly \\([\\text{RNA}]_{\\text{ss}} \\ast \\text{Length}\\). In this simulation, we will make the simplifying assumption that all transcripts are the same length, and will thus only need to consider the relative steady-state abundances of each RNA. Thus, the parameters that we need to set are:\n\nThose determining the rate constant distributions from which we sample transcript-specific ksyn’s and kdeg’s.\nThe total number of reads in our library. These will be randomly divided among the various simulated transcripts.\nThose determining the U-content distribution from which we sapmle transcript-specific U-content’s.\n\nDeciding 1) and 3) is often best done through comparing candidate distributions to real data, and choosing parameters that make the simulated data look as close to the real data as possible. The result of this may look like:"
  },
  {
    "objectID": "posts/post-with-code/index.html#summary",
    "href": "posts/post-with-code/index.html#summary",
    "title": "Introducing NR-seq by simulating NR-seq",
    "section": "Summary",
    "text": "Summary\nIn this post, we introduced NR-seq, and built a simulation of NR-seq data to explore several aspects of NR-seq data. In the next post, we will discuss various strategies for analyzing this data, using the simulation we built here to test our strategies."
  }
]